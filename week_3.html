<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <!--Bootstrap CSS CDN-->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <!--Custom CSS-->
    <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
    <script src="javascript.js"></script>
    <title>Week 3</title>
</head>
<body>
    <div class="wrapper">

        <!--Sidebar-->
        <nav id="sidebar">
            <div class="sidebar-header">
                <h3>Augmenting Communication</h3>
            </div>

            <ul class="list-unstyled components">
                    <li>
                        <a href="index.html">About</a>
                    </li>
                    <li>
                        <a href="#weeklyBlogs" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle">Blogs</a>
                        <ul class="collapse list-unstyled" id="weeklyBlogs">
                            <li>
                                <a href="week_1.html">Week 1</a>
                                <a href="week_2.html">Week 2</a>
                                <a href="week_3.html">Week 3</a>
                            </li>
                           
                        </ul>
                    </li>
                    
                    
                    
                </ul>


        </nav>


        <!--Page Content-->
        <div id="content">
            <div>
                <h2>Week 3: Storyboarding</h2>
                
                <p> </p>

                <img src="storyboard2.png" width="600" height="400">
                <p>
                    This week we reviewed the storyboard I developed over spring break. My design utilizes an augmented reality mobile application to perform object recognition and augment a virtual character signing the object’s name in ASL. The first three scenes illustrate one potential user scenario where both the parent and infant gaze at the toy car. The parent then brings forth the phone within both of their visual fields. Through the AR app, which projects the virtual character next to the toy car, the infant can receive linguistic input and associate what’s being signed with the object (and hopefully acquire vocabulary in sign language with repetitive use of the app). There are a couple of drawbacks to this design, which we discussed on Tuesday’s meeting. As opposed to being nonobtrusive, the design requires the parent to interrupt the infant’s focus of attention by always placing the phone between the infant and the object, which might work against what we’re trying to achieve. Second, the user scenario suggests that the parent will have to be sitting besides the infant. However, when we’re trying to track the gaze or focus of attention of someone usually we place ourselves in front of them instead of beside them. In this case, the phone will have to be uncomfortably placed between the parent and child, with the screen only facing the child. By addressing these drawbacks, we were able to modify the design.                </p>

                <img src="design2.jpg" width="600" height="400">
            
                <p>
                    The new design incorporates an overhead camera, which tracks the coordinate positions of the objects placed on the table and with the help of the eye tracking device communicate with the rest of the system which object is drawing the child’s attention. In this scenario, the child is sitting in the baby chair while the parent is directly across from them. After the system is notified of the infant’s object of interest the visual indicator is prompted, which is only visible to the parent. This helps to avoid distracting the infant. Here, we will be able to communicate with the parent the child’s visual focus and hopefully encourage the parent to be visually sensitive in their communicative behaviors. Another take on this design is utilizing a wearable haptic device that indicates the parent which object the child is looking at. Since where at the initial stage of drafting this design, we haven’t decided how we will introduce ASL instruction. For next week, I’ll look into the available eye tracking tools in the university’s digital media lab and see how we can further improve the current design.
                    
                </p>
                <h9>Published on March 24, 2019</h9>
                    
                    
                        


                
                
           

            </div>
            

        </div>

    </div>
    

    <!-- jQuery CDN - Slim version (=without AJAX) -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <!-- Popper.JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.0/umd/popper.min.js" integrity="sha384-cs/chFZiN24E4KMATLdqdvsezGxaGsi4hLGOzlXwp5UZB1LY//20VyM2taTB4QvJ" crossorigin="anonymous"></script>
    <!-- Bootstrap JS -->
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js" integrity="sha384-uefMccjFJAIv6A+rW+L4AHf99KvxDjWSu1z9VI8SKNVmz4sk7buKt/6v9KI65qnm" crossorigin="anonymous"></script>
    
</body>
</html>